Date: 2025-07-20
Topic:
  - link: 
    text: |
      タイトル：バイオインタラクション研究会　一般公開講演2025「宇宙と生命・タンパク質」
      イベント情報

      開催情報
      日時	2025年6月28日（土）
      9：30-12：20/14：00-15：00

      場所	ナイル
      料金	無料
      ※要申込

      いのち輝く未来社会のデザイン」をテーマとする大阪・関西万博が開催される中
      未来に向けた「宇宙と生命・タンパク質」をテーマとして分子の構造を科学的側面から理解し、
      宇宙へと広がるサイエンス分野への関心を醸成する取り組みを実施

      ・9：30-12：20　国内外の研究者による講演
      （休憩）
      ・14：00-15：00　JAXA宇宙飛行士　古川聡　氏　講演「国際宇宙ステーションからその先へ」
  - link: 
    text: |
      タイトル：Apple「Liquid Glass」は失敗か、革命か？ 美しさと可読性の狭間で揺れる新デザインが賛否両論を巻き起こす
      Appleが世界開発者会議（WWDC 2025）で発表したiOS 26の新たなデザイン言語「Liquid Glass」。それは、まるで水滴やガラスのような透明感と光の屈折を取り入れた、美しいインターフェースだった。しかし、そのベールが剥がされると同時に、世界中のユーザーやデザイナーから「美しい」という称賛と、「致命的に読みにくい」という痛烈な批判が同時に噴出。ネット上は今、賛否両論の嵐に見舞われている。

      このLiquid Glassは、Appleのデザインを新たな次元へと導く革命なのか、それとも機能性を犠牲にした「迷走」の始まりなのだろうか？

      衝撃のデザイン刷新、「Liquid Glass」とは何か？
      まず、この論争の中心にある「Liquid Glass」とは一体何なのかを正確に理解する必要がある。これはiOS 26、iPadOS 26、macOS 26といったAppleの主要なプラットフォームに横断的に導入される、次世代の統一デザイン言語だ。

      その最大の特徴は、Appleの空間コンピュータ「Vision Pro」のOS（visionOS）から着想を得た、その名の通り「液体のようなガラス」を模した光学的な表現にある。アイコンやメニュー、通知といったUI要素が、背景の上に「浮遊するガラス層」として描かれる。このガラスは半透明で、背景の色や形をぼんやりと透かし見せ、光が当たるとエッジで屈折するような効果までシミュレートされている。

      ios 26 liquid glass control
      筆者も実際にiOS 26ベータ版をインストールしてみたが、その変化は劇的だ。これまでのフラットなデザインに慣れた目には、すべての要素が光沢を帯び、ぬるりとした液体のように見える様は、強烈なインパクトを与える。Appleはこのデザインを「我々の歴史上、最も広範なデザインアップデート」と自信を見せるが、その先進性が、新たな問題の火種となってしまった。


      「美しい」「新鮮だ」- デザイナーたちを魅了した新たな美的感覚
      まずは、Liquid Glassに対する意見は批判一辺倒でないことは強調しておかねばならない。多くのデザイナーやクリエイターが、その技術的な洗練と新たな美的価値を高く評価している。

      Mac用クリーンアップアプリで知られるMacPawのソフトウェアエンジニア、Serhii Popov氏はWiredの取材に対し、「本当に新鮮な見た目だ」と称賛し、「UIとのインタラクションがより快適になるだろう」と期待を寄せる。また、スタートアップのデザインを支援するIterationの共同創業者Josh Puckett氏は、「Appleがデジタルな表面に感情を取り戻していることに興奮している」と述べ、これがより表現力豊かなソフトウェアへのトレンドを牽引することを望んでいる。

      その美しさは具体的なディテールに宿る。TechCrunchは、ガラスのように作り込まれた新しいアイコンや、滑らかに変形する「モーフィングボタン」、そしてUI要素が移動する際に背景のアイコンをガラス越しに歪ませるブラー効果など、細部へのこだわりに感心する声が紹介されている。

      この動きは競合他社にも衝撃を与えたようだ。スマートフォンメーカーNothingのCEOであるCarl Pei氏は自身のX（旧Twitter）アカウントで「Liquid Glass… なんだか好きかもしれない」と投稿。未来のUIのあり方を探る同氏にとって、Appleの新たな挑戦は無視できないものだったのだろう。

      「読めない」「これは敵対的デザインだ」- 噴出する深刻な批判
      しかし、その美しさは諸刃の剣だった。ベータ版を試したユーザーから真っ先に上がったのは、「テキストが読みにくい」という、UIの根幹を揺るがす深刻な問題だった。

      致命的なまでの「可読性の低さ」
      Mediumで辛辣なレビューを公開したライター、Derick David氏は、Liquid Glassを使った後「頭痛がした」と述べ、「これはユーザビリティの悪夢だ」「敵対的なデザインだ」とまで断じている。彼が指摘するのは、半透明のメニューやボタンの上にあるテキストが、背景と混ざり合って著しく読みにくくなるという問題だ。まるで「汚れた窓越しに文字を読もうとしているかのようだ」という比喩は、多くのユーザーが感じたであろうストレスを的確に表現している。

      この問題は、特に通知センターやコントロールセンターで顕著だ。ユーザーが設定した壁紙の色、特に明るい色の壁紙によっては、通知の白いテキストが背景に溶け込んでしまい、判読が極めて困難になる。


      筆者は特に写真アプリにおいて、縦長写真を表示しているときにサムネイルと写真が溶け込んで視認性が著しく損なわれることが気になった。

      S 19709958
      写真アプリでスクリーンショットを表示した時
      驚くべきことに、この問題はAppleが公開したApple Musicの公式プロモーション画像においてすら確認でき、半透明のバーに表示されたアーティスト名が非常にかすれて見えにくい。これが「完成形」として承認された画像だとすれば、Appleの品質管理に対する疑念が生じても不思議ではない。


      「アクセシビリティの悪夢」か？
      可読性の問題は、必然的にアクセシビリティ（誰もが情報にアクセスしやすいこと）への懸念につながる。前述のDavid氏は、「もうすぐ60歳になる私の母は、これを絶対に嫌がるだろう」と述べ、小さな文字や低コントラストのインターフェースに苦労している高齢者にとって、このデザインがいかに厳しいものであるかを訴える。

      Redditのスレッドでは、この問題はさらに深く議論されている。「アクセシビリティの悪夢」というコメントに対し、「設定でコントラストを上げればよい」という反論も出る。しかし、それに対して「アクセシビリティ設定をオンにすると、今度はデザインがひどく醜くなる」という再反論がなされている。

      あるユーザー（yuusharo氏）は、「美しさとアクセシビリティは両立できるはずだ。Appleがそれを達成したとは、少なくともこのベータ版では思えない」と鋭く指摘する。これは重要な論点だ。優れたデザインは、視覚にハンディキャップのないユーザーだけのものであってはならない。この点で、Liquid Glassはまだ答えを出せていない。

      過去とのデジャヴ：Windows Vista「Aero Glass」とiOS 7の記憶
      この混乱を見て、長年のテクノロジーウォッチャーは二つの過去の出来事を思い出しているだろう。一つはMicrosoftのWindows Vista、もう一つはApple自身のiOS 7だ。

      Windows Vista「Aero Glass」の再来、そして失敗
      Windows Centralは、「AppleのLiquid Glassは、Microsoftが2006年に発表したAero Glassの悪い模倣だ」と手厳しい。Windows VistaやWindows 7で採用されたAero Glassも、半透明のガラス効果をUIに取り入れた先進的なデザインだった。

      windows vista aero
      Windows VistaのAero Glassデザイン
      しかし、両者には決定的な違いがある。Aero Glassは、ガラスの背後にある要素がほとんど見えなくなるほど強い「ぼかし（ブラー）」をかけることで、手前にあるテキストの可読性を常に確保していた。一方で、Liquid Glassは透明度が高すぎるために背景が透けて見えすぎてしまい、結果としてテキストが読みにくくなっている、というのが同メディアの分析だ。Redditでも「Windows Vistaで見たやつだ」というコメントが散見され、多くのユーザーが同様の印象を抱いていることがわかる。

      Appleは、現在の強力なプロセッサ性能を活かして、Aero Glassがなし得なかったリアルな光の屈折効果まで実装した。しかし、その技術的な挑戦が、かえってUIに不要なノイズ（視覚的な妨げ）を生み出し、ユーザビリティを損なっているのだとすれば、皮肉な結果と言わざるを得ない。

      iOS 7が辿った「酷評から標準へ」の道
      もう一つの重要な比較対象が、2013年に登場したiOS 7だ。それまでの立体的なデザイン（スキューモーフィズム）を捨て、フラットデザインへと舵を切ったこのアップデートも、発表当初は「アイコンが子供っぽい」「細すぎるフォントが読みにくい」と、まさに今回と同じような酷評の嵐にさらされた。

      しかし、Appleは開発者向けベータ期間中にユーザーからのフィードバックを受け、フォントの太さやコントラストを大幅に調整した。そして秋の正式リリースまでには、多くの問題が改善され、今では誰もが当たり前のものとして受け入れている。

      これについて多くのメディアが、このiOS 7の歴史を繰り返し指摘している。つまり、今回のLiquid Glassも、あくまで「最初の開発者向けベータ版」に過ぎず、今後数ヶ月の間に大幅な改善が加えられる可能性が極めて高い、という見方だ。

      未完の大器か、迷走の始まりか – Liquid Glassの行方
      現時点で判断するならば、AppleのLiquid Glassは「未完の大器」と評するのが最も妥当だろう。

      その美的感覚や技術的な洗練は、間違いなく次世代のUIの可能性を感じさせる。しかし、その輝きは、ユーザビリティとアクセシビリティという、ソフトウェアデザインにおける最も基本的な原則を曇らせてしまっている。デザイナーのAdam Whitcroft氏が言うように、「ユーザーの注意を本来の目的から逸らすようなUIは、道を間違えている」のだ。

      今後、Appleがユーザーや開発者の声にどこまで耳を傾けるかが、Liquid Glassの運命を左右する。焦点となるのは、デザイナーたちが口を揃えて指摘する「透明度とぼかしのバランス調整」だろう。可読性を確保できるレベルまで不透明度を上げるのか、あるいは背景に応じてコントラストを動的に調整するような、より洗練された解決策を提示するのか。

      秋の正式リリースに向けて、Appleは静かに、しかし大胆にこのデザインを磨き上げてくるはずだ。その時、Liquid Glassは、iOS 7のように誰もが認める新たなスタンダードへと昇華しているのか。それとも、美しいだけの「失敗作」として記憶されるのか。我々は今、Appleのデザイン史における、極めて重要な分岐点を目撃しているのかもしれない。
  - link: 
    text: |
      タイトル：Google I/O の発表まとめ
      tl;dr
      Google I/O 2025 でたくさんのサービスや機能が発表されたよ
      イベントに合わせて公開されたものはすべてひと通りまとめたよ
      発表だけでまだ使うことのできないサービスも多いよ（アメリカ限定も多い）
      しばらく追記していくよ
      これはなに？
      Google I/O 2025 の発表をまとめたもの。開発者向けに限らず、よくばって発表内容をおおよそ網羅した（書きかけのため予定）ので、気になるところだけ読んでください。発表内容が豪勢で、悲しいかな、徹夜をしてしまったので、せっかくなのでみなさんの時短になれば＆自分の覚え書きとしてまとめています。少しでも参考になれば幸いです。



      こちらに今回の発表に関わる全 27 記事が一覧になっており、それらの中から押さえておくべき記事をかいつまんで簡潔にまとめます。

      発表動画（Keynote）について




      計約三時間の実況中継。場所はマウンテンビューの Shoreline Amphitheatre、Google I/O 参加のために私は現地に足を運んだことはありませんが、コロナ期以外は例年こちらの会場でやっているようです。X のタイムラインを見ていると現地参加の方をちらほら見かけました。X のタイムラインを観測するに、日本の方々もカリフォルニアにいるかの如く、みなさん夜更かしされていたようです。おつかれさまです。

      動画内で触れられたことについてはほぼ本記事でまとめていますが、やはりスマホが自律的に動く様子や帰ってきた Google Glass などはデモを見た方がわかりやすいと思います。ぜひご覧ください。



      また、Google I/O 2025 の公式 YouTube にて発表内容を 10 分でまとめた動画も公開されています。



      Gemini API の発表について


      Google I/O から数日後に公開された Gemini API に絞って解説した公式記事。

      LMarena で Gemini 2.5 Flash Preview が 2 位を達成、Gemini 2.5 Pro と Flash に 24 言語対応の複数話者対応のテキスト音声合成機能を追加、WebSocket に対応したリアルタイム音楽生成 Lyria RealTime、複雑な数学の問題やコーディングに対するリーズニング機能 Gemini 2.5 Pro Deep Think、スマホやタブレット端末向けに最適化されたオープンウェイトモデル Gemma 3n などなど。

      Google Beam と Google Meet のリアルタイム翻訳について


      Google が Project Starline について発表したのは 2021 年の Google I/O。離れていてもそばにいるかのような体験を画面越しに行なう、それが Project Starline でした。今回発表された Google Beam は四年の技術のアプデを開発に取り込んだ AI ファーストのビデオコミュニケーションプラットフォーム。6 台のカメラと AI を用いて、ビデオストリームをマージ、3D ライトフィールドディスプレイでレンダリング。ミリ単位のヘッドトラッキング、60 fps を実現、没入感のある体験を作り出します。HP と提携して、今年の後半に Google Beam デバイスが提供される予定。

      また、Google Meet にてリアルタイム音声翻訳ができるように。Google AI Pro / Ultra のサブスク契約をされている方が利用可能。ただし、現状英語とスペイン語間の翻訳のみで、今後数週間で言語の拡充を予定。

      Project Astra について


      Project Astra は Gemini 2.5 Pro を世界モデルへと拡張、視覚を備え、多言語を使い、感情を認識し、操作のできるユニバーサル AI アシスタントを構築する研究。Project Astra を Gemini アプリに統合、日常的なタスクの実行や管理などを行ないます。

      AI Mode について


      AI Mode はリーズニングやマルチモーダルを兼ね備えた AI 検索ツール。単なるウェブ検索ではなく、Gemini 2.5 Pro を用いて複数のクエリを同時に実行するクエリファンアウトを用いて、質問やウェブサイトの情報を深く掘り下げます。Deep Search で何百回と検索を実行し、レポーティング、Search Live でカメラを用いたリアルタイム対話ができるよう。ユースケースとしては、Google Pay によるチケット購入や予約などのタスクの実行から、ショッピング体験の向上、検索結果のパーソナライズ、カスタムチャートなど。Google 検索の画面に「AI Mode」が追加されます。登録不要。ただし、現状米国のみ。

      Gemini Diffusion について




      テキストやコードを高速に生成する拡散言語モデル。ノイズから段階的に出力を洗練する手法を用いて、一度に複数のトークンを生成することで高速化（1479 tps）。LiveCodeBench で 30.9%、BigCodeBench で 45.4%、HumanEval で 89.6%、AIME 2025 で 23.3%。ウェイトリスト登録は下記のリンクから。もしリンクが切れていたら上の記事より辿ってください。



      ウェイトリスト登録から数時間後に Gemini Diffusion が使えるようになりました。さすがに拡散言語モデルはレスポンスが速いですね。



      Gemini Code Assist について








      2 月にプレビュー版を公開していた Gemini Code Assist を正式リリース。VSCode、JetBrains、GitHub 経由で。GitHub 経由だと Install を押して、紐付けたいリポジトリを選ぶだけなのですぐ終わります。

      Jules について


      Google I/O の直前に公開されていた Gemini 2.5 Pro 搭載の自律型コーディングエージェント Jules。昨日時点ではウェイトリスト登録が必要な方もいたようでしたが、この発表と同時に公開ベータとなり、全世界で使えるようになりました。おそらく今読んでいるあなたも使えるはず。Google Cloud 上の仮想マシン内で閉じ、非同期で作業。テストの作成や機能の実装、バグ修正など。ベータ期間中は無料だが、有料化を予定。

      Gemini 2.5 について




      !
      URL は異なるのになぜか同じ記事🤔

      みんな大好き Gemini。今回の発表では Gemini 2.5 Pro と Gemini 2.5 Flash のどちらのモデルにも手を加えられました。

      Gemini 2.5 Pro では Deep Think という、回答を生成する前に複数の仮説を検討する強化リーズニングモードが試験的に導入。Deep Think を利用した Gemini 2.5 Pro は数学において現状最も難しいベンチマークのひとつである 2025 USAMO で o3 high を差し置いて 2 倍をうわ回るスコアを達成（下記図）、コーディングにおける難易度の高いベンチマーク LiveCodeBench でリード、マルチモーダル性能を測る MMMU で o3 と同等程度のスコアを達成しました。



      また、Gemini 2.5 Flash Preview 05-20 が Google AI Studion にて公開。ベンチマーク性能が高いのはもちろん、20-30% のトークン効率化、答えに辿り着くのに必要なトークン数が減りました。



      Gemini 2.5 Pro と Gemini 2.5 Flash のいずれのモデルも音声出力に対応。これは次の節にまわします。



      最新の LMArena の評価では一位が Gemini-2.5-Pro-Preview-05-06、二位が Gemini-2.5-Flash-Preview-05-20、三位が o3-2025-04-16 です。ベンチマークはベンチマークでしかないものの、英語圏ではどちらも人間の好みにかなり沿っているモデルだと言えるかなと思います。

      Gemini の音声出力について


      Gemini API はテキスト読み上げに使うことができます。Gemini API がおもしろいのは、指定できる話者はひとりだけではなく、複数人の話者を指定できるところ。スタイルやアクセント、ペース、トーンはすべて自然言語で指示することが可能です。試せてはいないですが、ストリーミングやファイル保存もできるようです。対応言語は 24 言語、声の選択肢は 30 種類。上述のように、対応しているモデルは gemini-2.5-pro-preview-tts と gemini-2.5-flash-preview-tts のふたつ。

      公式ドキュメントの Google AI Studio への案内リンクはなぜか機能していなかったため、Google AI Studio の Generate Speech のページから試してみました。もし下記のページが開けなければ、サイドバーより「Generate Media」をクリック、「Gemini speech generation」を開いてください。





      声質はいい感じ。ただ、若干ハルシネーション（LLM 単体ではないのでなんと呼ぶかわからないが）によって、テキストをそのまま読み上げてくれないことがあったりするので、ワークフローを組むときはその後の音声を文字起こしして一致しているか評価するなど、少し一手間工夫は必要に思います。その上で、擬似 NotebookLM のように完全自動ポッドキャスト生成なんてことはみなさんなら造作もないですね。

      安全性について


      Gemini 2.5 Pro の安全性に関するホワイトペーパー。間接的プロンプトインジェクションを仕掛ける場合、悪意あるユーザの指示と通常のユーザの指示を区別できないため、Automated Red-teaming（ART）を実施。単純な攻撃には十分有効ではあるものの、基本的な防御戦略（スポットライティングや自己反省など）は単純な攻撃には有効だが、適応型の攻撃には脆弱であることを発見。対策として、モデルを強固にしたり、入出力のチェックを入れたり、システムレベルのガードレールを組み合わせました。結果として、通常のタスク性能を維持しつつも、攻撃成功率を大幅に低減、Gemini 2.5 を最も安全性の高いモデルとすることができました。

      Gemma 3n について












      Gemma 3n はモバイル端末向けのオープンウェイトモデル。TPU で 11T を食わせたテキスト、画像、音声、動画のマルチモーダルモデル。入出力はどちらも 32k まで。Gemma 3n E2B と Gemma 3n E4B のふたつのモデルが公開。それぞれパラメータ数は 5B / 8B ではあるが、メモリ使用量は 2GB / 3GB で済むよう。レスポンスは Gemma 3 4B の 1.5 倍。アーキテクチャには MatFormer を採用。手法そのものは 2023 年に公開された下記の論文。次節にて。



      Google AI Edge と Google AI Studio で利用可。ただし、Hugging Face Hub にあるモデルはテキストと画像のみの入力に限定。

      Google AI Studio から動かしてみました。一応動作はするものの、エラーになってレスポンスが返ってこないことが頻繁に発生しました。時間を置いて安定してからもう少し触ってみます。



      MatFormer について


      再掲。Mat はマトリョーシカの頭、Former は Transformer の尻尾。一般的なトランスフォーマーのブロックの中にフィードフォワードネットワークを入れ子状に入れ込んだもの。

      [追記予定]

      SynthID Detector について


      AI 生成コンテンツにおける透かしの話。SynthID Detector は Google の AI によって生成されたテキスト、画像、音声、動画における透かしを検出。目的は誤情報の阻止。コンテンツをアップロードすると透かしのある部分を特定、検出してくれます。NVIDIA と提携し、一部のサービスに SynthID が埋め込まれている。ウェイトリストの登録は下記のリンクから。入力項目が少ないのですぐに終わります。よろしければ。



      Veo 3 と Imagen 4、Flow、Lyria 2 について


      Veo 3 は単なる動画生成でなく音声付きの動画を生成してくれます。画像生成モデルの Imagen 4 はクオリティの向上はさながら、文字に対する指示に従うように。これらに Gemini を組み合わせた Flow という AI 映像作成ツールも合わせて発表。カメラコントロールやリファレンス付きの動画生成、アウトペインティング、オブジェクトの追加や削除などの機能も取り入れています。また、Lyria 2 というは音楽制作ツールも公開。これらのすべての出力には透かしがついています。詳しくは SynthID Detector の節を参照。

      Veo 3 について


      Veo 3 は音声付きの動画を生成できる動画生成モデル。物理法則に則ったリアルな最高 4k の動画を生成。Veo 2 から画像を参照して動画を生成することができますが、それに加えてアウトペインティング（画像だとイメージがつきやすいですが、動画の場合単純に数秒伸ばすイメージ）他いろんな制御ができるようです。Flow、Gemini アプリ、Google AI Studio、Vertex AI Studio で利用可能。SynthID による透かしが埋め込まれています。

      Google AI Studio のサイドバー「Generate Media」より「Veo」がありますが、そちらでは現状 Veo 2 のみで Veo 3 は未対応でした。楽しみ。



      Imagen 4 について


      Imagen 4 は画像生成モデル。

      [追記予定]

      Flow について




      Flow は AI 映像制作ツール。動画生成の Veo 3、画像生成の Imagen、マルチモーダルモデルの Gemini を組み合わせて、自然言語から高品質な物理法則に忠実に従ったリアルな映像を生成できます。自前でアセットを用意するか、あるいは Flow で生成したものをアセットとして使うこともできる。カメラコントロール、シーンの作成、アセット管理、Flow TV など。現在利用できるのは米国のみ。Google AI Pro / Google AI Ultra のサブスクで使えます。



      もしアメリカにいらっしゃる方はこちらから。私は日本にいるので残念ながら使えませんでした😭

      Flow is not available in your country yet.

      代わりに案内されたページはこちら。



      Flow で作成された動画がテレビのようにひたすら流れてきます。非現実な動画ばかり流れてくるので見るのはほどほどにしておくことをおすすめします。だんだん頭が痛くなってきます。

      音楽生成 Lyria 2 について








      Lyria 自体は 2023 年の 11 月に公開された音楽生成モデル。YouTube Shorts 用の音声を作ることができるようです。この頃から生成した音楽にこの後触れる透かし技術である SynthID が埋め込まれています。今回発表された Lyria 2 は Lyria のメジャーアップデート。高品質の商用利用のできる水準の音楽を生成できる点がウリ。テキストプロンプトで音楽を生成できるのはもちろん、キーや BPM 他いくつか設定を制御できるよう。ウェイトリスト登録はこちらから。



      Lyria RealTime というのも公開されており、こちらはインタラクティブに音楽を生成できるツールとなっています。Google AI Studio のサイドバーより「Generate Media」をクリック、「Lyria RealTime」から試すことが可能です。私は音楽なんもわからんので、使い勝手はみなさんの感想にお任せします。Google AI Studio から使えるということは、API からも使えるということです。





      AI Agent の構築について


      オープンソースのフレームワーク（LangGraph、CrewAI、LlamaIndex、Composio）を用いて、Gemini をベースとした AI エージェントを構築する方法の概要を記した記事。AI エージェント開発に Gemini を推している理由として、リーズニング＆プランニングが得意、Function calling、マルチモーダル、コンテキストウィンドウの大きさの四つがあげられています。ちなみに、コンテキストウィンドウは近日 1M から 2M になるよう。これは前々から言っていたと思いますが笑

      LiteRT について






      LiteRT は以前は TensorFlow Lite と呼ばれていた Google のモバイル端末向けランタイム。モバイル端末で問題になる待機時間、プライバシー、接続の安定性、モデルサイズ、バッテリー消費を解決するために開発されたもの。Android や iOS などのスマホはもちろん、組み込み、マイクロコントローラーなどのクロスプラットフォーム対応。TensorFlow や PyTorch、JAX のモデルを FlatBuffers フォーマット（拡張子は .tflite）に変換したのち推論可能。Java、Kotlin、Swift、Objective-C、C++、Python などに対応。

      Google AI Edge について




      まだ飲み込めるくらい理解できていませんが、前節の LiteRT 向けのモデルの量子化ツール。

      Agent 関連のツール、プロトコルについて


      Agent Development Kit（ADK）の話。Python ADK v1.0.0 安定版のリリースに加えて、Java ADK v.0.1.0 のリリース。Agent2Agent（A2A）プロトコルが v0.2 に更新。Auth0、Box、Microsoft、SAP、Zoom などの企業との A2A パートナーシップが拡大。

      Stitch について




      Stitch は自然言語、画像入力から UI デザインとフロントエンドのコードを生成できるツール。Gemini 2.5 Pro のマルチモーダル機能を用いてプロンプトから UI を生成、画像や手書きのスケッチからインターフェースを作成、複数バリエーションを生成、Figma へ貼り付け。

      MedGemma について












      医療ドメインのマルチモーダルのオープンウェイトモデル。Gemma 3 をベースに 4B の VLM と 27B の LLM の二種類を用意。胸部 X 線他医療ドメインの匿名化されたデータで学習。VLM のイメージエンコーダには SigLIP を採用。Context Length は 128k。ユースケースに応じてファインチューニングあるいはプロンプトエンジニアリング、エージェンティックオーケストレーションなどで出力を調整することが推奨されています。利用には Health AI Developer Foundation の利用規約への同意が必須。Hugging Face Hub 他 Google Cloud Model Garden からも利用できます。

      Gemini in Chrome について








      Gemini in Chrome は Google Chrome に Gemini が組み込まれたもの。現時点で、インターネット回遊中に今開いているページの情報の解説を頼んだり、要約をしてもらったり。今後、複数タブを横断し、ウェブサイトをナビゲートしてくれるようになるようです。Google AI Pro（月額 $19.99）あるいは Google AI Ultra（月額 $249.99）のサブスク契約している方が対象者ですが、こちらも米国限定です。言語設定が英語になっていないといけないようです。

      ブラウザエージェントを用いて人と AI とのインタラクションがどうなるのかについての研究プロジェクトである Project Mariner からスピンオフしたもののよう。こちらはマルチモーダルリーズニングによってウェブのエレメントを解析、解釈し、ユーザの求めるゴールに対してプランニング＆実行することを目的としています。

      Google AI Ultra について


      Google AI Ultra は月額 $249.99 の全部乗せプラン（最初の三ヶ月は半額）。今日発表された Gemini 2.5 Pro の Deep Think や Veo 3、Flow、Project Mariner を始めとして、YouTube Premium やストレージ拡張などもりもりの機能で、Google AI の VIP パスと表現されています。

      Flow や Gemini in Chrome を使いたいなら Pro 以上。Project Mariner を使いたいなら Ultra 以上の契約が必要です。ただし、今はまだ米国限定です。



      Android XR について


      [追記予定]

      MCP 対応について


      公式ドキュメントの Function calling のページに詳細は書いてありました。Function calling はモデルを外部ツールや API と接続、通常のテキスト生成をするのではなく、関数を呼び出して実行する機能。OpenAI が初出と認識していますが、Gemini API でももちろん対応。Model Context Protocol（MCP）についてここで詳しく解説することはいたしませんが、公式ドキュメントの言葉を借りるなら「AI アプリケーションを外部ツールやデータソース、システムに接続するためのオープンスタンダード」です。

      [追記予定]

      まとめ
      津波のように押し寄せる新しいサービス、デモに圧倒されて、不覚にも寝ることを忘れてしまいました。さすが Google ですね。追記予定となっているところは適宜勉強して埋めていきます。お読みいただきありがとうございました。
  - link: 
    text: |
      タイトル：「どの都道府県の給与が高いか」や「人口と給与は関係あるのか」など日本の膨大な情報を見やすく表示するダッシュボード「Japan Dashboard」をデジタル庁が公開したので使ってみた
            
      内閣府とデジタル庁が経済・財政・人口・暮らしに関する情報を見やすくまとめた「Japan Dashboard」を公開しました。都道府県ごとの人口や平均給与などを確認したり、各種情報の相関関係を調べたりすることができてデータ好きにはたまらないダッシュボードとなっています。

      Japan Dashboard（経済・財政・人口・暮らしに関するダッシュボード）とデータカタログ｜デジタル庁
      https://www.digital.go.jp/resources/japandashboard

      Japan Dashboardでは人口に関する指標や経済に関する指標など合計691指標をサクッと確認できます。



      各種指標を閲覧するには、まずJapan Dashboardの公開ページにアクセスして説明を読みながら下方向にスクロールします。



      すると、指標が表形式で表示されます。今回は図で確認したいのでそのまま下方向にスクロール。



      ページをスクロールしていくと都道府県ごとの指標を確認できる画面が表示されます。初期状態では各都道府県の人口が表示されています。



      スマートフォンだと以下のように小さく表示されるので、PCやタブレットで閲覧するのがオススメ。



      左側のメニューで表示する指標を変更できます。例えば「15歳未満の人口」をクリックすると各都道府県の15歳未満の人口が表示されます。



      大分類で「経済」、中分類で「所得・課税」、指標で「現金給与総額・1人当たり」を選択すると、各都道府県の給与の高さが一発で分かります。



      「指標をグラフでみる」をクリックしてから「数値順」をクリックすると、都道府県を給与の高い順に並び替えたグラフを表示可能。東京が最も高く、その後に愛知、大阪、神奈川と続いています。



      さらに下方向にスクロールすると、2つの指標の関係性を確認できる画面が表示されます。この画面ではY軸とX軸の指標をそれぞれ指定して、2つの指標の関係性をチェックできます。



      例として人口と給与の関係性を確かめてみます。まず、「Y軸の指標を選ぶ」をクリックしてから大分類は「経済」、中分類は「所得・課税」、指標は「現金給与総額・1人当たり」を選択。



      続いて「X軸の指標を選ぶ」をクリックして、大分類は「人口」、中分類は「人口」、指標は「人口総数 | 人口推計」をクリック。



      これで、人口と給与の関係性を確かめられるようになりました。相関の強さは0.76(1に近いほど相関が強い)です。東京、大阪、愛知、神奈川などを見ると人口に比例して給与が上がっているようにも見えますが、人口の比較的少ない都道府県は団子状になっていて相関が弱めです。



      Japan Dashboardでは、上記のように数多くの指標を確認したり関係性を調べたりすることが可能。以下のように4種の指標を並べて表示する機能も用意されているので、データ好きなら何時間でも触り続けられます。


  - link: 
    text: |
      タイトル：【現地レポート】北海道スペースポートから国内初の海外ロケット発射–4年ぶりの打ち上げで感じた熱気

      　2025年7月12日午前11時40分、澄み切った十勝晴れの空に、一筋の白煙が力強く描かれた。この日、北海道大樹町の宇宙港「北海道スペースポート（HOSPO）」から打ち上げられたのは、台湾の宇宙開発企業tiSPACEの日本法人jtSPACEが開発した全長12mの準軌道（サブオービタル）ロケット「VP01」。国内初となる海外企業のロケット打ち上げとなった。


      打ち上げの準備をする「VP01」（出典：北海道スペースポート）
      　既報の通り、VP01は目標高度の100kmには届かなかった。打ち上げ後の解析によれば、VP01は高度4km（速報値）に到達し、ランチャーの機能、分離機能、2段目の再点火など、ロケットの一部システムの動作を検証した。ロケット2段目は分離後、ミッションを遂行できないと判断し、飛行停止措置をとった。2段目の機体は射点から北1km未満の当縁川付近の警戒区域内の町有地に落下した。

      　結果としては失敗に終わったが、HOSPOとしても2021年にインターステラテクノロジズの「MOMO」6号機を打ち上げて以来、実に4年ぶりの打ち上げ。当日は久しぶりのロケット発射を見届けようと地元住民をはじめ多くの見学者が訪れた。ここでは、期待と興奮に包まれた現地の様子をレポートする。

      延期アナウンス、そして突如のカウントダウン
      　打ち上げ当日の朝8時50分。見学会場となったHOSPOの滑走路には、地元住民や親子連れ、宇宙ファンなど多くの見学者が詰めかけ、会場は次第に熱気を帯びていった。天候は若干の薄曇り。地表付近には緩やかな風が吹き、絶好の観覧日和となった。来場者は思い思いに見学場所を選び、jtSPACEのロゴ入りの帽子やグッズを手に、打ち上げへの期待を膨らませていた。


      晴天なこともあり地元住民をはじめ北海道内外から多数の見学者が訪れた

      会場ではさまざまなグッズが販売された
      　予定されていた打ち上げ時刻は午前10時50分。しかし10時44分、見学会場に「安全確保の確認のため、打ち上げ時間を延期します」とのアナウンスが響き渡る。少し緊張の糸が緩む中、「正午までの打ち上げで調整中」との説明もあり、訪れた人々は静かにその時を待った。 そして、突如として「11時40分に打ち上げます」との最終アナウンス。発表からわずか2分後に迫る発射時刻に、会場は一気に緊張感に包まれた。


      jtSPACEの管制室
      「VP01」ロケットが飛び立ち来場者から歓声
      　HOSPOを整備するSPACE COTAN代表取締役社長 兼 CEOの小田切義憲氏によるカウントダウンと共に、黒い機体が火を噴き、滑走路の先の木々の間からVP01は発射された。轟音と共に空へ駆け上がるその姿に、見学者からは「おお、行った！」と歓声が上がった。


      SPACE COTAN代表取締役社長 兼 CEOの小田切義憲氏
      　固体燃料ロケットならではの高速上昇を見せ、順調に見えたVP01の飛行だったが、打ち上げから約10秒後に、機体の挙動に異変が生じた。姿勢制御が乱れ始め、機体は蛇行。約50秒後にはエンジン音が突然途絶え、燃焼が終了したことが明らかとなった。その直後、陸地側へ向けてロケットの2段目と思われる黒い円筒状の物体が落下する様子も目撃された。


      「VP01」打ち上げの瞬間（出典：jtSPACE）
      飛行停止措置、そして明かされた「失敗」という結果
      　発射直後の興奮から一転、会場には不穏な空気が漂った。打ち上げの成否が分からない中、大樹町職員やHOSPO関係者が慌ただしく動く様子が目立ち始めた。そして午前11時59分、小田切氏が報道陣の前で「飛行停止措置が取られた」と説明。VP01の打ち上げが失敗に終わったことが正式に発表された。


      状況を確認する大樹町職員やHOSPO関係者
      　打ち上げが失敗に終わったにも関わらず、会場には多くの感動の声が聞かれた。愛知県から訪れたという男性は、「黄色とオレンジの炎がはっきりと見えた。初めて生でロケットの打ち上げを見たが、とても感動した」と目を輝かせた。HOSPO関係者も「今回の試みでは多くの経験を得ることができた。改善点も明らかになったので、次の挑戦に必ずつなげていきたい」と前向きな姿勢を見せた。

      　今回は残念な結果となったが、国内初の海外ロケットの打ち上げは、北海道大樹町が“宇宙の玄関口”として成長していくうえでの新たな一歩と言えるだろう。
      
  - link: 
    text: |
      タイトル：神奈川県「衛星データ利活用プロジェクト」を公募開始

            

      神奈川県は2025年7月10日、衛星データを活用した新ビジネス創出を目指す 「衛星データ利活用プロジェクト」 の公募を開始しました。県内で実施される案件を対象に、1件あたり最大600万円 が支援されます。

      プロジェクトには資金助成に加え、知財や課題解決の専門家による伴走支援も提供されます。県はモデルケースを通じて、衛星データ市場のユースケース拡大と県内産業の底上げを狙います。

      募集概要
      採択枠：3件程度
      支援額：上限600万円（税込）／件（プロジェクト終了後に精査のうえ確定）
      支援期間：覚書締結日から2026年2月28日まで（令和8年2月末）
      応募要件・資格
      以下の要件を満たすプロジェクトが対象となります。

      衛星データの利活用により、社会課題の解決または市場ニーズへの対応を図るものであること
      原則として1年以内に事業化の方向性を見出すことができ、一定の成果（実証実験、試行導入、 顧客ヒアリング結果など）を得られる計画を有すること
      本事業以外に、県から同一内容で他の委託・補助を受けていないこと
      また、プロジェクトメンバーの中に神奈川県県内に拠点を持つ企業が含まれることが必須となっています。

      募集期間や手続き
      応募期間：2025年7月10日（木）〜8月6日（水）17時必着
      ※企画提案書の提出に先立ち、7月30日（水曜日）17時までに参加意思表明書の提出が必要

      応募に関する詳細は、神奈川県の公式ウェブサイトに掲載されている募集要項を参照してください。
  - link: 
    text: |
      タイトル：ラピダスが２ナノ半導体の試作に成功－トップらが迅速な成果強調

      次世代半導体の量産を目指すラピダスは18日、北海道千歳市で２ナノメートル（ナノは10億分の１）半導体の試作に成功したと発表した。世界的にも注目されるこの技術開発はラピダスにとって大きな一歩だが、2027年の量産に向けては依然として課題も残る。

      　　技術的に難易度の高い試作を成功させた背景には、極端紫外線（ＥＵＶ）露光装置の迅速な導入があった。小池淳義社長は記者会見で、昨年末の装置搬入から「わずか３カ月でＥＵＶの露光が成功したのは世界に例がない」と振り返った。

      relates to ラピダスが２ナノ半導体の試作に成功－トップらが迅速な成果強調
      2nm GAAトランジスタ試作ウェーハSource: Rapidus Corp.
      　　小池社長によると、次世代の半導体プロセスを支える重要技術であるＧＡＡ（ゲートオールアラウンド）トランジスタの試作を行ってから、動作確認されたのは７月10日のことだった。今年度中にはチップ設計に必要なプロセス・デザイン・キット（ＰＤＫ）を顧客に提供し、顧客が自社製品の設計を始めるための環境を整える。

      　　一方で懸念も拭い切れない。試作品には未だ改良の余地が残り、トランジスタ性能や歩留まりの向上が必要になるためだ。

      　　ここ数年、政府の後押しもあり、半導体業界には追い風が吹いてきた。政府が熊本県に誘致した半導体受託生産最大手の台湾積体電路製造（ＴＳＭＣ）の第１工場は24年末に生産を始めた。22年設立のラピダスも、出資を含め累計１兆8000億円超の支援を受けている。

      　　ただ足元では不透明感も漂い始めている。ＴＳＭＣは否定しているが、熊本第２工場の建設が先送りされるのではないかという観測も浮上した。また東京商工リサーチによると、パワー半導体のファウンドリー（受託生産）を手がけるＪＳファンダリ（東京都港区）は14日に、東京地裁に破産を申請し、破産開始決定を受けた。

      　　政府は、先端半導体の受託生産がＴＳＭＣに集中するのはリスクであり、２ナノ半導体の量産を目指すラピダスの存在はリスクを軽減する上で「意義がある」との見解を示して支援を続けている。だが、20日投開票の参院選で与党の立場が弱まるようなことになれば、同社の支援に対する議論が高まりかねない。

      　　きょうの会見で東哲郎会長は、「単に10数年遅れた日本が最先端の技術に挑戦しているだけでなく、世界でもまれに見る異例のスピードでここまできていることに世界が非常に驚いている」として、工場の建設を担った鹿島や装置・材料メーカーなど関係者への感謝を述べた。